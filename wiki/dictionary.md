# Dictionary

**Distributed representation:**  
Distributed representation is a compact dense vector representing an object created a with neural networks. Distributed representation for symbolic data was introduced by Hinton (1985).

**Discrimative models:**
Discriminative models draw boundaries in the data space. A discriminative model focuses on predicting the labels of the data.

**Generative models:**
Generative models try to model how data is placed throughout the space. A generative model focuses on explaining how the data was generated.

**Heterogeneous:**  
*Stacking* often considers heterogeneous weak learners, learns them in parallel, and combines them. In other words; it use different base learning algorithms to directly ensure ensemble diversity.

**Heterogeneous data:** 
Data with large variation. For example, patients are typically a very heterogeneous population as they differ with many factors including demographics, diagnostic test results, and medical histories.

**Homogenous:**  
A data set is homogeneous if it is made up of things that are similar to each other.  
*Bagging* and *boosting* used homogenous weak learners for ensemble.

**Representation learning:**  
Representation learning aims to learn representations of rawdata as useful information for further classification or prediction. Some methds are; *K-mean clustering*, *PCA* and *ICA*.  
*Distributed representation* is also form of representation learning made with neural networks.

**Likelihood:**
https://stats.stackexchange.com/questions/2641/what-is-the-difference-between-likelihood-and-probability